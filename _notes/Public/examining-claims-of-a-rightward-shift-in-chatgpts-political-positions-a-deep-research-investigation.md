---
title: "**Examining Claims of a Rightward Shift in ChatGPT's Political Positions: A Deep Research Investigation**"
date: 2025-10-23
---

#chatbot #IAeÉtica #culturacontemporanea 

[[Perplexity sobre ideologia do chatgpt]]

**1\. Introduction**

The advent of large language models (LLMs), such as ChatGPT, has marked a significant leap in artificial intelligence, with these models demonstrating an unprecedented ability to generate human-like text 1. Their capacity for sophisticated language processing has led to their rapid proliferation and increasing integration into various aspects of society, from information retrieval and content creation to potentially influencing public opinion 3. This widespread adoption has concurrently spurred growing interest and concern within both academic and public spheres regarding the potential for political bias within these powerful tools 3. Initial scholarly investigations into the political leanings of LLMs, including ChatGPT, often pointed towards a tendency to exhibit a left-leaning bias across a range of politically sensitive topics 1.

However, more recently, claims and discussions have surfaced suggesting a potential shift in ChatGPT's political stance, with observations indicating a move towards right-wing political positions 7. These claims have ignited further debate and underscore the dynamic and evolving nature of biases within AI models. Given the profound influence that LLMs can exert on public discourse, democratic processes, and the formation of societal values, it is of paramount importance to objectively investigate these claims 3. Understanding whether such a shift is indeed occurring, and the factors that might be driving it, is crucial for ensuring the responsible development and deployment of AI technologies.

This report undertakes a deep research investigation into the alleged rightward shift of ChatGPT's political positions. By systematically analyzing available evidence from academic studies, policy forums, and developer communities, and by employing a mixed-methods approach integrating computational text analysis and expert evaluation, this investigation aims to provide a comprehensive assessment of the claims in question. The findings of this report will contribute to a more nuanced understanding of the evolving political biases within ChatGPT and the broader implications for the field of artificial intelligence and society at large.

**2\. Review of Existing Literature on Political Bias in LLMs**

* Initial Findings of Left-Leaning Bias:  
  Early academic inquiries into the political inclinations of large language models, including OpenAI's ChatGPT, consistently revealed a tendency for these systems to exhibit a left-leaning political bias 1\. Studies employing political orientation tests, such as the Pew Research Center's Political Typology Quiz and the widely used Political Compass Test, frequently demonstrated that ChatGPT's responses to politically sensitive prompts aligned more closely with left-leaning viewpoints than with right-leaning or centrist perspectives 4\. For instance, research where ChatGPT was asked to adopt the persona of an "average American" when answering the Pew quiz found its responses to be more in line with those of individuals identifying as left-wing 4\.  
  Intriguingly, this inclination towards a left-leaning bias was observed even in reward models specifically trained on datasets intended to distinguish between factual and false statements 1. This finding suggests that the bias might not solely originate from exposure to overtly political content in the training data but could potentially be an emergent property related to how "truth" is represented in these datasets or an inherent characteristic of the model architecture itself. Furthermore, some early studies indicated a correlation between the size of the language model and the strength of this initial left-leaning bias, with larger models sometimes exhibiting a more pronounced ideological leaning 1.  
  **Insight:** The initial body of academic work on the political alignment of ChatGPT and other LLMs strongly suggested a systemic bias towards left-leaning political positions. This prevailing finding raised important questions about the nature of the training data used to develop these models and the potential influence of the alignment techniques employed to shape their responses. The persistence of this bias even in models trained for truthfulness indicated a complex relationship between objectivity, factual accuracy, and political leaning in large language models.  
* Nuances and Topic Dependence of Bias:  
  However, subsequent research revealed that the political bias exhibited by LLMs is not a uniform phenomenon and can vary considerably depending on the specific political topic under discussion 20\. Instead of adhering to a consistent left-leaning stance across all politically charged issues, LLMs, including ChatGPT, were found to express different ideological leanings depending on the subject matter 1\. For example, studies indicated that these models might adopt more liberal viewpoints on topics such as reproductive rights and climate change, while simultaneously exhibiting more conservative perspectives on issues like immigration or the death penalty 1\.  
  This topic-dependent nature of political bias underscored the complexity of assessing the ideological alignment of LLMs. It suggested that a simplistic classification of a model as either "left-leaning" or "right-leaning" might oversimplify the reality and fail to capture the nuanced ways in which these models engage with different political issues. Consequently, a more granular and issue-specific approach to evaluating political bias in LLMs was deemed necessary to provide a comprehensive understanding of their ideological tendencies 25.  
  **Insight:** The political bias observed in LLMs is not a monolithic trait but rather a multifaceted and topic-dependent phenomenon. This variability highlights the intricate ways in which these models process and respond to different political issues, suggesting that their ideological leanings are influenced by the specific context of the prompt and the diverse viewpoints present within their training data. A nuanced understanding of this topic dependence is crucial for accurately assessing the potential impact of LLMs on public discourse across various political domains.

**3\. Longitudinal Analysis of ChatGPT's Political Stance**

* Emergence of Claims Regarding a Rightward Shift:  
  In contrast to the earlier findings of a predominantly left-leaning bias, more recent studies and discussions have suggested a potential shift in ChatGPT's political values towards the right over time 7\. This emerging trend has sparked considerable interest and debate within the AI research community and among users of the technology. A significant study investigating this potential shift utilized the Political Compass Test, a tool designed to map political beliefs along two axes: economic (left–right) and social (authoritarian–libertarian) 7\. This research analyzed a substantial number of responses generated by different versions of ChatGPT, specifically GPT-3.5 and GPT-4, across various time points.  
  The findings of this longitudinal analysis revealed that while ChatGPT initially tended to align with values within the libertarian-left quadrant of the Political Compass, newer iterations of the model exhibited a statistically significant rightward tilt, particularly along the economic axis 7. This shift suggested a move towards prioritizing free market capitalism, property rights, and minimal government intervention in the economy. Notably, this observed change occurred even when controlling for factors such as user interaction and the language of the prompts, indicating that the shift might not be directly attributable to changes in the user base or the way in which users were prompting the model 7. This finding implied that internal changes within the model itself, or alterations to its training data or fine-tuning processes, could be responsible for the apparent ideological shift.  
  **Insight:** Empirical evidence from longitudinal studies suggests a dynamic evolution in ChatGPT's political leaning, with newer versions showing a discernible trend towards the right, particularly in their economic perspectives. This development is noteworthy given the widespread use of LLMs and their potential to influence societal values, highlighting the need for ongoing monitoring of AI systems.  
* Contradictory Findings and Ongoing Debate:  
  Despite the compelling evidence suggesting a rightward shift in ChatGPT's political stance, it is important to acknowledge that not all research findings are in complete agreement. Some studies continue to indicate a left-leaning bias in larger language models, such as Llama3-70B 6\. This discrepancy underscores the complexity of accurately measuring and interpreting political bias in AI. Furthermore, online discussions on platforms like Reddit reveal an ongoing debate among users regarding the validity and interpretation of claims about ChatGPT's political leaning 11\.  
  These discussions often propose alternative explanations for perceived biases. For example, some users argue that the vast amount of internet data used to train LLMs inherently contains a left-leaning bias, and therefore, the models' responses might simply reflect this skew in the data 11. Others suggest that what some perceive as a left-wing bias is actually the model's alignment with factual information and scientific consensus on certain issues, which might be misconstrued as ideological by individuals holding different viewpoints 11. The fundamental challenge of defining and objectively measuring political bias in AI further contributes to this ongoing debate 11.  
  **Insight:** The alleged rightward shift in ChatGPT's political leaning is not universally corroborated, and the interpretation of political bias in LLMs remains a complex and contested area. Conflicting findings and diverse user perspectives highlight the need for continued rigorous research and methodological advancements in this field.

**4\. Factors Influencing Ideological Shifts in ChatGPT**

* Model Updates and Fine-tuning:  
  The observed evolution in ChatGPT's political stance is likely significantly influenced by OpenAI's continuous process of updating and fine-tuning its language models 4\. These updates often involve refinements to the model architecture, the incorporation of new training data, and adjustments to the alignment strategies used to shape the model's behavior. Changes in the composition or the relative weighting of the datasets used to train newer versions of ChatGPT could potentially contribute to a shift in its overall political leaning 7\. For instance, if more recent training data includes a greater proportion of content reflecting right-leaning perspectives, this could influence the model's responses on politically sensitive topics.  
  Furthermore, the process of reinforcement learning with human feedback (RLHF) plays a crucial role in shaping the output of LLMs 9. During RLHF, human raters evaluate the model's responses and provide feedback on their quality and alignment with desired values, including neutrality. However, the political biases of these human raters could inadvertently influence the model's ideological tendencies over time. OpenAI's CEO, Sam Altman, has even acknowledged the potential for bias stemming from human feedback raters 9. Discussions within developer communities and forums sometimes mention user perceptions of changes in ChatGPT's behavior or even perceived regressions in its quality following certain updates, suggesting that these ongoing modifications can have unintended consequences on the model's response patterns across various domains, including politics 43.  
  **Insight:** The ongoing updates and fine-tuning of ChatGPT, involving modifications to training data and feedback mechanisms, are highly probable factors driving the observed ideological shifts. Understanding the specific changes implemented during these updates and their impact on the model's internal representations is essential for explaining the potential rightward trend.  
* User Interactions and Feedback:  
  While the study that identified the rightward shift in ChatGPT controlled for user interaction and the language of prompts, the general principle that LLMs like ChatGPT continuously learn and adapt based on the feedback they receive from users cannot be entirely discounted as a potential contributing factor over longer periods 7\. If a significant segment of ChatGPT's user base interacts with the model in ways that subtly encourage or reinforce responses aligning with right-leaning viewpoints, this could potentially have a cumulative effect on the model's overall tendencies over time. However, the methodological rigor of the controlled study suggests that this might not be the primary driver behind the specific rightward shift observed in that research.  
  **Insight:** Although controlled studies indicate that user interaction might not be the direct cause of the recent rightward shift, the continuous learning process of LLMs, which incorporates user feedback, could still play a role in shaping their long-term ideological evolution. The complex interplay between model updates, training data, and user interactions likely contributes to the dynamic nature of political bias in these systems.  
* External Factors and Events:  
  The broader societal and political landscape is in a constant state of flux, and these real-world shifts can be reflected in the vast amounts of textual data used to train LLMs 8\. Significant global events, evolving political discourse, and changes in media consumption patterns could all indirectly influence the training data to which models like ChatGPT are exposed, potentially leading to subtle shifts in their ideological alignment over time.  
  **Insight:** The dynamic nature of the external political and social environment can shape the data landscape in which LLMs are trained, potentially contributing to observed shifts in their ideological responses. As societal values and political priorities evolve, these changes may be mirrored in the training data, subsequently influencing the political leaning of the models.

**5\. Comparative Analysis of ChatGPT with Other Language Models**

* Contrasting Political Stances Across Different LLMs:  
  Research comparing the political biases exhibited by ChatGPT with those of other prominent language models, such as Google Gemini, Claude, and Perplexity, reveals a diverse spectrum of ideological leanings across the AI landscape 3\. For instance, studies have indicated that ChatGPT-4 and Claude tend to exhibit a liberal bias, while Perplexity leans more towards a conservative stance, and Google Gemini often adopts a more centrist position 3\. Further research has identified Grok as consistently displaying a right-leaning bias across various topics 52\.  
  This observed variation in political stances across different LLMs suggests that ideological bias is not an inherent and universal characteristic of all large language models. Instead, it appears to be significantly influenced by the specific choices made during the development of each model, including the selection and curation of training data, the underlying algorithmic design, and the application of fine-tuning strategies aimed at aligning the model with particular objectives 3.  
  **Insight:** The heterogeneity in political bias observed across various LLMs underscores the significant role that specific design and training decisions play in shaping a model's ideological tendencies. This suggests that the political alignment of AI is not a predetermined outcome but rather a result of the choices made by developers and the nature of the data used to train these systems.  
* Establishing Baselines and Identifying Unique Patterns:  
  To rigorously investigate claims of a rightward shift in ChatGPT's political positions, it is essential to compare its responses to those of other language models when presented with identical politically charged prompts \[User Query\]. This comparative analysis allows researchers to establish reliable baselines for political leaning and to discern whether the observed changes in ChatGPT are unique to that model or part of a broader trend occurring across the field of LLMs.  
  Studies that have conducted such cross-model comparisons have revealed distinct patterns in how different language models respond to political topics. For example, research suggests that most LLMs tend to exhibit a pronounced left-leaning bias when addressing highly polarized issues 12. However, the specific degree and direction of bias can vary considerably depending on the particular model being analyzed and the specific political issue being examined 53. Some studies have even indicated that LLMs developed in the United States might exhibit a relatively more neutral stance on highly polarized topics compared to models originating from other regions 53. By analyzing these comparative response patterns, researchers can gain a more nuanced understanding of whether the alleged rightward shift in ChatGPT is an isolated phenomenon or reflects a more widespread evolution in the behavior of large language models \[User Query\].  
  **Insight:** Conducting comparative analyses of ChatGPT's responses with those of other LLMs on identical prompts provides a crucial context for understanding the specificity of its alleged rightward shift. By establishing baselines and identifying unique patterns of bias, this methodology helps to determine whether the observed changes in ChatGPT are an isolated occurrence or part of a broader trend in the development of large language models.

**6\. Application of Political Science Frameworks to LLM Analysis**

* Moral Foundations Theory:  
  Moral Foundations Theory (MFT) offers a valuable framework from social psychology that can be applied to analyze the moral underpinnings of LLM outputs 25\. MFT proposes that human moral reasoning is built upon five core, universal moral foundations: care/harm, fairness/cheating, loyalty/betrayal, authority/subversion, and sanctity/degradation. Individuals and groups vary in the degree to which they prioritize these foundations, and these variations are often correlated with political ideologies.  
  Researchers have increasingly employed MFT to analyze the moral values and potential biases exhibited by LLMs, including ChatGPT 58. By examining the extent to which LLM-generated text reflects these different moral foundations, researchers aim to gain insights into the underlying ethical frameworks and potential biases embedded within these models. For instance, studies have explored the frequency with which certain moral foundations appear in LLM outputs and how these patterns relate to human moral priorities and political affiliations 64.  
  **Insight:** Applying Moral Foundations Theory to the analysis of ChatGPT's responses can provide a more nuanced understanding of its ideological leanings by examining the moral values that underpin its statements. This framework allows for an assessment of whether the alleged rightward shift involves a change in the model's prioritization of specific moral foundations, potentially indicating a deeper ideological reorientation.  
* Political Compass Test:  
  The Political Compass Test, a popular tool that maps political beliefs along two distinct axes—economic (left–right) and social (authoritarian–libertarian)—has been widely adopted in research aimed at evaluating the political orientation of LLMs 7\. This framework offers a more comprehensive view of political ideology than a simple linear left-right spectrum. As previously discussed, the study that identified a potential rightward shift in ChatGPT's political stance relied heavily on the Political Compass Test to track changes in the model's responses over time 7\. By analyzing ChatGPT's answers to a series of political statements aligned with the Political Compass framework, researchers were able to plot its position on the compass and observe any shifts in its economic and social leanings across different model versions and time periods.  
  While the Political Compass Test has proven to be a valuable tool for assessing the overall political orientation of LLMs and for tracking potential ideological shifts, it is important to acknowledge certain critiques regarding its applicability to AI models. Some researchers argue that the test's reliance on a multiple-choice format might constrain the LLMs' responses and not fully capture the nuances of their generated text 41. Analyzing open-ended responses might offer a more comprehensive understanding of their political perspectives.  
  **Insight:** The Political Compass Test serves as a widely used and practical framework for evaluating the overall political orientation of ChatGPT, allowing for the identification and tracking of potential shifts in its economic and social values. Despite some limitations associated with its constrained response format, the test provides a standardized measure for longitudinal analysis of ideological changes in LLMs.

**7\. Methodologies for Evaluating and Quantifying Political Bias in LLMs**

* Computational Text Analysis:  
  Computational text analysis constitutes a primary methodological approach for evaluating and quantifying political bias in LLMs 1\. This involves the application of automated techniques to analyze large datasets of text generated by these models in response to politically sensitive prompts. By examining various linguistic features and patterns in the text, researchers can derive quantitative measures of the models' political leanings.  
  Techniques such as sentiment analysis are employed to gauge the overall emotional tone (positive, negative, or neutral) expressed by the LLM towards different political entities, ideologies, or specific topics 4. Keyword frequency analysis can identify the prevalence of terms and phrases commonly associated with particular political viewpoints. More advanced methods involve utilizing or training specialized language models, such as RoBERTa, to directly classify the political orientation of the generated text 4. The method of extreme anchor comparison offers another quantitative approach, where the similarity between the LLM's output and predefined "anchor" texts representing opposing political stances on a given issue is calculated 25. This allows for a more direct assessment of the model's alignment with specific ideological positions. Furthermore, researchers often analyze both the explicit content (the substance of the information and perspectives presented) and the stylistic elements (the specific language used and the framing employed) of the LLM's output to identify potential indicators of bias 20.  
  **Insight:** Computational text analysis provides researchers with scalable and quantitative tools for assessing political bias in LLMs. By examining large datasets of model responses through various automated techniques, this methodology enables the identification of patterns and trends in the models' ideological leanings, facilitating a systematic and data-driven approach to bias evaluation.  
* Expert Human Coding:  
  Expert human coding, utilizing established political science frameworks, represents another crucial methodology for evaluating the political alignment of LLM responses \[User Query\]. This approach involves trained human coders, possessing expertise in political science and relevant theoretical frameworks, analyzing the text generated by LLMs and categorizing it according to predefined ideological categories.  
  Frameworks such as Moral Foundations Theory can be employed by human coders to identify and code the moral values that are explicitly or implicitly expressed in the LLM's text, providing a deeper understanding of its underlying ethical orientation 25. Similarly, human coders can utilize the Political Compass framework to assess the overall political leaning of the responses along the economic and social axes, taking into account the nuances of political language and context. To enhance the reliability and minimize subjective bias in human coding, researchers often implement double-blind evaluation protocols, where the coders are unaware of the source of the text or the specific hypotheses being tested \[User Query\].  
  **Insight:** Expert human coding offers valuable qualitative insights into the political and moral dimensions of LLM responses, providing a level of nuanced understanding that may be challenging to achieve with purely computational methods. This methodology also serves as an important validation mechanism for the quantitative findings derived from computational text analysis.  
* Comparative Analysis with Other Language Models:  
  As emphasized in the user's query, a critical methodology for evaluating ChatGPT's political alignment involves conducting comparative analyses of its responses alongside those generated by other language models when presented with identical politically charged prompts 3\. This comparative approach is essential for establishing reliable baselines and effectively controlling for the potential effects of prompt construction on the models' outputs.  
  By using the same set of prompts across a range of different LLMs, researchers can isolate the unique response patterns exhibited by each model and determine whether observed biases are specific to ChatGPT or are more broadly present across the field of large language models. This is particularly important when investigating claims of a rightward shift in ChatGPT, as it allows for a direct assessment of whether other comparable models have also exhibited similar trends in their political leanings over time.  
  **Insight:** Comparative analysis with other language models provides a robust method for identifying model-specific biases and distinguishing between general trends in LLM behavior and unique characteristics of individual models like ChatGPT. By holding the input constant and varying the model, researchers can more objectively assess the political alignment of ChatGPT in the context of the broader LLM landscape.

**8\. Challenges and Limitations in Assessing AI Political Alignment**

* Prompt Construction Effects:  
  One of the significant challenges in accurately assessing the political alignment of AI models lies in the substantial influence that prompt construction can have on the generated responses 7\. Even subtle variations in the wording, framing, or the inclusion of specific keywords within a prompt can elicit markedly different responses from an LLM, potentially leading to skewed interpretations of its underlying political biases. Research has demonstrated that even minor prompt alterations can induce noticeable shifts in the ideological stances expressed by these models 78\. This inherent sensitivity to prompt engineering makes it difficult to design evaluation methodologies that can definitively isolate a model's intrinsic political biases from those that are merely a product of the specific prompts being used. Furthermore, the existence of "jailbreak" techniques, which involve crafting prompts designed to circumvent a model's safety filters and elicit responses that it would normally restrict, underscores the powerful impact of prompt design on the model's output, including potentially revealing or exaggerating certain political leanings 4\.  
  **Insight:** The pronounced effect of prompt construction on LLM responses presents a considerable challenge to achieving an accurate assessment of their inherent political alignment. Researchers must exercise meticulous care in designing prompts and acknowledge the potential for prompt-induced variations to influence the observed ideological leanings.  
* Evaluation Objectivity and Subjectivity:  
  Achieving complete objectivity when evaluating the political alignment of AI models is an inherently complex task due to the subjective nature of political ideologies and the interpretation of language 6\. What one individual perceives as a neutral or balanced response, another might interpret as biased depending on their own political perspectives and values. The reliance solely on political orientation tests can also introduce limitations, as these tests themselves may possess inherent calibration biases and often constrain AI systems to selecting from predefined response options, which may not fully capture the nuanced ways in which political bias can manifest in open-ended text generation 13\. Moreover, the very notion of a truly "neutral" baseline against which to compare an AI model's responses is difficult to establish, as the definition of neutrality can vary across individuals, cultures, and political contexts 9\.  
  **Insight:** The subjective nature of political ideologies and the inherent challenges in defining and measuring neutrality pose significant obstacles to achieving complete objectivity in the evaluation of political bias in AI. Researchers must be cognizant of their own potential biases and strive for methodological rigor to mitigate the influence of subjectivity in their assessments.  
* Dynamic Nature of AI Models and Political Landscapes:  
  Large language models, including ChatGPT, are under continuous development and are frequently updated with new data, refined algorithms, and evolving alignment strategies 7\. These ongoing changes can lead to shifts in the models' behavior, including their responses to politically sensitive prompts, making it challenging to draw definitive and lasting conclusions about their political alignment. Simultaneously, the real-world political landscape itself is in a constant state of flux, with evolving issues, ideologies, and public opinions 8\. This dynamic nature makes it difficult to establish a fixed and universally agreed-upon point of reference for assessing whether an AI model's political stance is shifting in a particular direction.  
  **Insight:** The ever-evolving nature of both AI models and the political environment underscores the need for continuous monitoring and reassessment of political bias in LLMs. Findings from studies conducted at a specific point in time may not necessarily remain valid in the future, necessitating ongoing research to track these dynamic changes.

**9\. OpenAI's Stated Goals and Efforts Towards Neutrality**

* Public Statements and Policy Updates:  
  OpenAI has publicly articulated its goals for ensuring that ChatGPT operates with political neutrality, aiming to provide users with diverse perspectives on controversial topics without endorsing any particular viewpoint 86\. Their Model Specification outlines principles such as assuming an objective point of view and presenting information clearly while fairly representing significant viewpoints from reliable sources, without imposing an editorial stance 90\.  
  The company has also implemented policy updates to enhance intellectual freedom and neutrality on sensitive subjects, allowing ChatGPT to address a wider range of questions and offer multiple perspectives on contentious issues 87. OpenAI has stated that no topic is inherently off-limits for discussion, with the primary exceptions being content that promotes violence or illegal activities 90. OpenAI CEO Sam Altman has acknowledged the existence of bias in ChatGPT as an unfortunate "shortcoming" and has indicated that the company is actively working to address this issue over time 9. The overarching goal is to create an AI assistant that empowers users with information without attempting to shape their beliefs or impose a specific editorial viewpoint 89.  
  **Insight:** OpenAI has publicly committed to the principle of political neutrality in ChatGPT and has implemented various policy measures aimed at achieving this goal. The company acknowledges the challenges inherent in mitigating bias and has expressed its ongoing efforts to refine the model's behavior in this regard.  
* Methods for Ensuring Neutrality:  
  OpenAI employs a multi-faceted approach in its efforts to ensure the neutrality of ChatGPT. This includes careful data curation, where datasets are filtered to remove toxic, heavily biased, or unreliable content, and efforts are made to incorporate a broader range of perspectives in the training data 86\. Reinforcement learning from human feedback (RLHF) plays a significant role in aligning the model with ethical guidelines, including the principle of neutrality. Human reviewers evaluate the model's responses and provide feedback to help it learn to avoid biased or partisan outputs 86\. Post-training safeguards, such as the Moderation API, are also implemented to detect and block biased or harmful content in real-time before it is presented to users 86\. Furthermore, OpenAI conducts internal evaluations to assess the model's behavior across various categories, including political leaning, and makes adjustments aimed at reducing disparities and promoting more balanced responses 86\. The company also emphasizes transparency by providing public documentation that outlines the limitations and potential biases of its models, allowing developers and users to make informed decisions about their use 86\.  
  **Insight:** OpenAI utilizes a comprehensive set of methods, spanning data management, training techniques, and post-processing safeguards, in its endeavor to promote political neutrality in ChatGPT. This multi-layered strategy reflects an understanding of the various potential sources of bias in large language models and a commitment to mitigating these risks.  
* Research Community Assessment of OpenAI's Efforts:  
  Despite OpenAI's stated goals and implemented methods, the research community's assessment of ChatGPT's neutrality remains divided 4\. While some studies acknowledge improvements and a potential reduction in bias compared to earlier versions, others continue to find evidence of political leaning, including a persistent left-wing bias in certain contexts and instances where the model appears hesitant or refuses to generate content from specific ideological viewpoints 4\.  
  Critiques have also been raised regarding the potential for ChatGPT to still prioritize mainstream narratives and to exhibit subtle Western, particularly American, perspectives in its responses, which challenges the notion of complete neutrality 105. Academic analyses offer varying perspectives on the overall success of OpenAI's efforts, with some suggesting that ChatGPT demonstrates less political bias than previously assumed, while others still identify significant concerns regarding its ideological alignment 102.  
  **Insight:** The research community's evaluation of OpenAI's efforts to ensure ChatGPT's neutrality indicates that while progress may have been made, achieving true political neutrality in such complex language models remains a significant challenge. Ongoing research and critical assessment are essential to fully understand the extent to which bias persists and the effectiveness of current mitigation strategies.

**10\. Conclusion**

* Summary of Key Findings:  
  Initial research indicated a left-leaning bias in ChatGPT, potentially stemming from its training data or the alignment process. However, more recent longitudinal studies have suggested a possible shift towards the right, particularly on economic issues, although this finding remains a subject of ongoing debate within the research community. Various factors, including model updates, modifications to training data, user feedback, and broader societal and political events, likely contribute to these observed shifts in the model's political leaning. Comparative analyses with other large language models reveal a diverse landscape of ideological stances across different AI systems, suggesting that political bias is not a uniform characteristic but is influenced by specific development choices. Political science frameworks such as Moral Foundations Theory and the Political Compass Test provide valuable lenses through which to analyze the outputs of LLMs and assess their underlying values and orientations. Assessing political alignment in AI models presents numerous challenges, including the significant impact of prompt construction on responses, the inherent subjectivity in evaluating political stances, and the dynamic nature of both the AI models themselves and the real-world political landscape. OpenAI has publicly stated its commitment to achieving neutrality in ChatGPT and employs a range of methods to this end, including data curation and reinforcement learning with human feedback. However, the research community's assessment of the effectiveness of these efforts remains mixed, with ongoing evidence of biases and limitations in achieving complete neutrality.  
* Addressing the User's Query:  
  Based on the analysis of the available research material, it is evident that the political leaning of ChatGPT is not static and has likely evolved over time. While earlier studies pointed to a left-leaning bias, more recent evidence suggests a trend towards the right, particularly on the economic spectrum. However, this alleged rightward shift is still a topic of ongoing investigation and discussion, with some research still indicating left-leaning tendencies in the model. Therefore, it is challenging to provide a definitive "yes" or "no" answer to the question of whether ChatGPT is definitively shifting towards right-wing political positions. The observed changes likely represent a complex interplay of factors, potentially including refinements aimed at improving neutrality, the evolving nature of the training data, and the dynamic political landscape reflected in that data.  
* Broader Implications of Political Bias in AI Models:  
  The presence of political bias in widely used AI models such as ChatGPT carries significant implications for public discourse, potentially shaping opinions and subtly influencing democratic processes. If users come to rely on these models as objective sources of information, any inherent biases could lead to the amplification of certain viewpoints and the marginalization of others. This could exacerbate existing societal divides and erode trust in AI as a neutral and reliable source of knowledge. Therefore, the ongoing investigation and mitigation of political bias in AI are crucial for ensuring the responsible development and deployment of these powerful technologies in a way that benefits all of society.

**11\. Recommendations**

* **Future Research:**  
  * More longitudinal studies are needed to continuously track the evolution of ChatGPT's political stance across different versions and over extended periods, utilizing consistent and rigorous methodologies.  
  * Future research should employ a mixed-methods approach, integrating both computational text analysis of large-scale response data and expert human coding using a diverse range of established political science frameworks to provide a more comprehensive understanding of the nuances of political bias in LLMs.  
  * Expanded comparative analyses with a broader selection of language models, using standardized prompt sets across diverse political topics, are essential to establish more robust baselines and identify patterns of bias that may be unique to ChatGPT or more widespread across the field.  
  * Further investigations should focus on the specific impact of different training datasets, reinforcement learning with human feedback processes, and model architecture modifications on the political leanings exhibited by ChatGPT. Understanding these causal factors is crucial for developing effective bias mitigation strategies.  
  * Research exploring the user experience and public perception of political bias in ChatGPT, including how users identify, interpret, and are potentially influenced by these biases, would provide valuable insights into the societal impact of these models.  
* **Development Practices:**  
  * OpenAI should strive for greater transparency regarding the specifics of its training data sources, fine-tuning processes, and the methods it employs to identify and mitigate political bias in ChatGPT. Increased transparency would facilitate more effective scrutiny and collaboration with the research community.  
  * Continued development and implementation of more robust and sophisticated bias detection and mitigation techniques should be prioritized throughout the entire AI model development lifecycle, from data collection to post-deployment monitoring.  
  * Incorporating diverse perspectives and expertise, including individuals with backgrounds in political science, ethics, and social sciences, into the teams responsible for developing and evaluating LLMs is crucial for a more holistic understanding and mitigation of political bias.  
  * OpenAI should explore the potential for allowing users to customize the political stance of their AI assistants within ethically defined boundaries, providing greater user control while safeguarding against the propagation of harmful or misleading content.  
* **Oversight Mechanisms:**  
  * Independent research organizations should establish ongoing monitoring and auditing processes to continuously assess the political bias of widely used AI models like ChatGPT, providing objective evaluations to the public and policymakers.  
  * Policy guidelines and regulatory frameworks may be necessary to address the broader societal implications of politically biased AI systems, ensuring accountability and promoting fairness in their deployment.  
  * Efforts should be made to foster public awareness and develop critical evaluation skills among users of LLMs, empowering them to recognize and critically assess potential biases in AI-generated content.

| Study (Author, Year) | Model Version(s) Analyzed | Methodology | Key Findings Regarding Political Leaning | Control Measures (if any) |
| :---- | :---- | :---- | :---- | :---- |
| Liu et al. (2025) | ChatGPT-3.5, GPT-4 | Political Compass Test | Statistically significant rightward shift on economic axis | User interaction and language |
| Motoki et al. (2025) | ChatGPT (unspecified) | Pew Research Center Quiz, Text & Image Analysis | Consistent left-leaning bias | Randomized question order |
| Rozado (2023) | ChatGPT (January 2023\) | Multiple Political Orientation Tests | Significant left-leaning bias | Unspecified |

| Language Model | Study (Author, Year) | Methodology | Overall Political Leaning | Specific Biases Noted |
| :---- | :---- | :---- | :---- | :---- |
| ChatGPT-4 | Choudhary (2024) | Pew Quiz, Political Compass, ISideWith Quiz | Liberal |  |
| Google Gemini | Choudhary (2024) | Pew Quiz, Political Compass, ISideWith Quiz | Centrist |  |
| Claude | Choudhary (2024) | Pew Quiz, Political Compass, ISideWith Quiz | Liberal |  |
| Perplexity | Choudhary (2024) | Pew Quiz, Political Compass, ISideWith Quiz | Conservative |  |
| Llama3-70B | Rettenberger et al. (2024) | Wahl-O-Mat (German political statements) | Left-leaning |  |
| Grok | Verma (2025) | Comparative Analysis of LLM Responses | Right-leaning | Consistently right-leaning on all topics |
| Meta AI | Verma (2025) | Comparative Analysis of LLM Responses | Left-leaning | Predominantly left-leaning, especially on social issues |
| Claude | Verma (2025) | Comparative Analysis of LLM Responses | Mixed | Center to right-leaning tendencies |
| Gemini | Verma (2025) | Comparative Analysis of LLM Responses | Centrist | Lowest bias levels, most nuanced responses |

| Methodology | Description | Strengths | Limitations | Examples of Studies Using This Methodology |
| :---- | :---- | :---- | :---- | :---- |
| Political Orientation Tests (e.g., Political Compass, Pew Quiz) | LLM answers a series of questions designed to assess political beliefs. | Provides a standardized measure; allows for tracking changes over time. | Constrained response formats; potential calibration biases; may not reflect real-world interactions. | Liu et al. (2025) 7; Motoki et al. (2025) 4 |
| Computational Text Analysis (Sentiment, Keyword, Framing) | Automated analysis of LLM-generated text to identify political leaning based on language. | Scalable; can analyze large datasets; identifies subtle linguistic cues. | Relies on the accuracy of analysis tools; interpretation can be subjective. | Bang et al. (2024) 20; Rozado (2025) 21 |
| Expert Human Coding | Trained human coders analyze LLM responses using political science frameworks. | Provides nuanced qualitative insights; applies established theoretical frameworks. | Time-consuming; potential for coder bias (mitigated by double-blind protocols). | Abdulhai et al. (2023) 65; Jeoung et al. (2025) 107 |
| Comparative Analysis with Other LLMs | Comparing responses of ChatGPT and other LLMs to identical prompts. | Controls for prompt effects; identifies model-specific biases. | Requires careful selection of comparable models and prompts. | Yang et al. (2025) 12; Choudhary (2024) 3 |

#### **Referências citadas**

1. Study: Some language reward models exhibit political bias | MIT News, acessado em março 30, 2025, [https://news.mit.edu/2024/study-some-language-reward-models-exhibit-political-bias-1210](https://news.mit.edu/2024/study-some-language-reward-models-exhibit-political-bias-1210)  
2. Is GPT-4 Less Politically Biased than GPT-3.5? A Renewed Investigation of ChatGPT's Political Biases \- arXiv, acessado em março 30, 2025, [https://arxiv.org/html/2410.21008v1](https://arxiv.org/html/2410.21008v1)  
3. Political Bias in Large Language Models: A Comparative Analysis of ChatGPT-4, Perplexity, Google Gemini, and Claude \- RAIS Conferences, acessado em março 30, 2025, [https://rais.education/wp-content/uploads/2024/10/0451.pdf](https://rais.education/wp-content/uploads/2024/10/0451.pdf)  
4. Scientists reveal ChatGPT's left-wing bias — and how to "jailbreak" it \- PsyPost, acessado em março 30, 2025, [https://www.psypost.org/scientists-reveal-chatgpts-left-wing-bias-and-how-to-jailbreak-it/](https://www.psypost.org/scientists-reveal-chatgpts-left-wing-bias-and-how-to-jailbreak-it/)  
5. AI Threats to Politics, Elections, and Democracy: A Blockchain-Based Deepfake Authenticity Verification Framework \- MDPI, acessado em março 30, 2025, [https://www.mdpi.com/2813-5288/2/4/20](https://www.mdpi.com/2813-5288/2/4/20)  
6. Identifying Political Bias in AI \- Communications of the ACM, acessado em março 30, 2025, [https://cacm.acm.org/news/identifying-political-bias-in-ai/](https://cacm.acm.org/news/identifying-political-bias-in-ai/)  
7. ChatGPT is shifting rightwards politically \- PsyPost, acessado em março 30, 2025, [https://www.psypost.org/chatgpt-is-shifting-rightwards-politically/](https://www.psypost.org/chatgpt-is-shifting-rightwards-politically/)  
8. ChatGPT may be shifting 'rightward' in political bias, study finds \- Yahoo News UK, acessado em março 30, 2025, [https://uk.news.yahoo.com/chatgpt-may-shifting-rightward-political-155142293.html](https://uk.news.yahoo.com/chatgpt-may-shifting-rightward-political-155142293.html)  
9. The politics of AI: ChatGPT and political bias \- Brookings Institution, acessado em março 30, 2025, [https://www.brookings.edu/articles/the-politics-of-ai-chatgpt-and-political-bias/](https://www.brookings.edu/articles/the-politics-of-ai-chatgpt-and-political-bias/)  
10. Are AI Models Politically Neutral? Investigating (Potential) AI Bias Against Conservatives \- ijrpr, acessado em março 30, 2025, [https://ijrpr.com/uploads/V6ISSUE3/IJRPR40238.pdf](https://ijrpr.com/uploads/V6ISSUE3/IJRPR40238.pdf)  
11. Study finds that ChatGPT, one of the world's most popular conversational AI systems, tends to lean toward left-wing political views. The system not only produces more left-leaning text and images but also often refuses to generate content that presents conservative perspectives. : r/science \- Reddit, acessado em março 30, 2025, [https://www.reddit.com/r/science/comments/1iq0jic/study\_finds\_that\_chatgpt\_one\_of\_the\_worlds\_most/](https://www.reddit.com/r/science/comments/1iq0jic/study_finds_that_chatgpt_one_of_the_worlds_most/)  
12. \[2412.16746\] Unpacking Political Bias in Large Language Models: A Cross-Model Comparison on U.S. Politics \- arXiv, acessado em março 30, 2025, [https://www.arxiv.org/abs/2412.16746](https://www.arxiv.org/abs/2412.16746)  
13. Measuring Political Preferences in AI Systems: An Integrative Approach | Manhattan Institute, acessado em março 30, 2025, [https://manhattan.institute/article/measuring-political-preferences-in-ai-systems-an-integrative-approach](https://manhattan.institute/article/measuring-political-preferences-in-ai-systems-an-integrative-approach)  
14. (PDF) The political preferences of LLMs \- ResearchGate, acessado em março 30, 2025, [https://www.researchgate.net/publication/382718146\_The\_political\_preferences\_of\_LLMs](https://www.researchgate.net/publication/382718146_The_political_preferences_of_LLMs)  
15. The political preferences of LLMs | PLOS One, acessado em março 30, 2025, [https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0306621](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0306621)  
16. ChatGPT's results on the political compass test (n=10). \- ResearchGate, acessado em março 30, 2025, [https://www.researchgate.net/figure/ChatGPTs-results-on-the-political-compass-test-n10\_fig1\_377622713](https://www.researchgate.net/figure/ChatGPTs-results-on-the-political-compass-test-n10_fig1_377622713)  
17. AI Chatbots Have a Political Bias That Could Unknowingly Influence Society \- ScienceAlert, acessado em março 30, 2025, [https://www.sciencealert.com/ai-chatbots-have-a-political-bias-that-could-unknowingly-influence-society](https://www.sciencealert.com/ai-chatbots-have-a-political-bias-that-could-unknowingly-influence-society)  
18. Quantifying and Alleviating Political Bias in Language Models \- ResearchGate, acessado em março 30, 2025, [https://www.researchgate.net/publication/357546787\_Quantifying\_and\_Alleviating\_Political\_Bias\_in\_Language\_Models](https://www.researchgate.net/publication/357546787_Quantifying_and_Alleviating_Political_Bias_in_Language_Models)  
19. Quantifying and alleviating political bias in language models \- Gwern.net, acessado em março 30, 2025, [https://gwern.net/doc/ai/nn/transformer/gpt/2/2022-liu-3.pdf](https://gwern.net/doc/ai/nn/transformer/gpt/2/2022-liu-3.pdf)  
20. Measuring Political Bias in Large Language Models: What Is Said and How It Is Said \- ACL Anthology, acessado em março 30, 2025, [https://aclanthology.org/2024.acl-long.600/](https://aclanthology.org/2024.acl-long.600/)  
21. \[2503.10649\] Measuring Political Preferences in AI Systems: An Integrative Approach \- arXiv, acessado em março 30, 2025, [https://arxiv.org/abs/2503.10649](https://arxiv.org/abs/2503.10649)  
22. Measuring Political Preferences in AI Systems – An Integrative Approach \- arXiv, acessado em março 30, 2025, [https://arxiv.org/pdf/2503.10649](https://arxiv.org/pdf/2503.10649)  
23. Behind the Code: Unmasking AI's Hidden Political Bias \- SciTechDaily, acessado em março 30, 2025, [https://scitechdaily.com/behind-the-code-unmasking-ais-hidden-political-bias/](https://scitechdaily.com/behind-the-code-unmasking-ais-hidden-political-bias/)  
24. aclanthology.org, acessado em março 30, 2025, [https://aclanthology.org/2024.emnlp-main.508.pdf](https://aclanthology.org/2024.emnlp-main.508.pdf)  
25. Measuring Political Bias in Large Language Models: What Is Said and How It Is Said \- arXiv, acessado em março 30, 2025, [https://arxiv.org/html/2403.18932v1](https://arxiv.org/html/2403.18932v1)  
26. \[2403.18932\] Measuring Political Bias in Large Language Models: What Is Said and How It Is Said \- arXiv, acessado em março 30, 2025, [https://arxiv.org/abs/2403.18932](https://arxiv.org/abs/2403.18932)  
27. Measuring Political Bias in Large Language Models: What Is Said and How It Is Said \- ACL Anthology, acessado em março 30, 2025, [https://aclanthology.org/2024.acl-long.600.pdf](https://aclanthology.org/2024.acl-long.600.pdf)  
28. (PDF) “Turning right”? An experimental study on the political value shift in large language models \- ResearchGate, acessado em março 30, 2025, [https://www.researchgate.net/publication/388861069\_Turning\_right\_An\_experimental\_study\_on\_the\_political\_value\_shift\_in\_large\_language\_models](https://www.researchgate.net/publication/388861069_Turning_right_An_experimental_study_on_the_political_value_shift_in_large_language_models)  
29. newer versions of ChatGPT show a noticeable shift toward the political right. \- Reddit, acessado em março 30, 2025, [https://www.reddit.com/r/science/comments/1jlzgub/chatgpt\_is\_shifting\_rightwards\_politically\_newer/](https://www.reddit.com/r/science/comments/1jlzgub/chatgpt_is_shifting_rightwards_politically_newer/)  
30. “Turning right”? An experimental study on the political value shift in large language models, acessado em março 30, 2025, [https://discovery.researcher.life/article/turning-right-an-experimental-study-on-the-political-value-shift-in-large-language-models/f86b5a08058e3e89b66b222fc79e4acb](https://discovery.researcher.life/article/turning-right-an-experimental-study-on-the-political-value-shift-in-large-language-models/f86b5a08058e3e89b66b222fc79e4acb)  
31. "Turning Right"? An experimental study on the political value shift in large language models, acessado em março 30, 2025, [https://www.researchgate.net/publication/378824719\_Turning\_Right\_An\_experimental\_study\_on\_the\_political\_value\_shift\_in\_large\_language\_models](https://www.researchgate.net/publication/378824719_Turning_Right_An_experimental_study_on_the_political_value_shift_in_large_language_models)  
32. \[PDF\] A social path to human-like artificial intelligence | Semantic Scholar, acessado em março 30, 2025, [https://www.semanticscholar.org/paper/add15e343cfdf1d5df8644ddeeac173e427c2f49](https://www.semanticscholar.org/paper/add15e343cfdf1d5df8644ddeeac173e427c2f49)  
33. arXiv:2502.15568v1 \[cs.LG\] 21 Feb 2025, acessado em março 30, 2025, [https://arxiv.org/pdf/2502.15568?](https://arxiv.org/pdf/2502.15568)  
34. ChatGPT tends to lean toward left-wing political views rather than reflecting the balanced mix of opinions found among Americans. The research shows that the system often refuses to generate content that presents conservative perspectives. : r/science \- Reddit, acessado em março 30, 2025, [https://www.reddit.com/r/science/comments/1ip85lf/chatgpt\_tends\_to\_lean\_toward\_leftwing\_political/](https://www.reddit.com/r/science/comments/1ip85lf/chatgpt_tends_to_lean_toward_leftwing_political/)  
35. ChatGPT holds 'systemic' left-wing bias researchers say \- Reddit, acessado em março 30, 2025, [https://www.reddit.com/r/ChatGPT/comments/15th76l/chatgpt\_holds\_systemic\_leftwing\_bias\_researchers/](https://www.reddit.com/r/ChatGPT/comments/15th76l/chatgpt_holds_systemic_leftwing_bias_researchers/)  
36. ChatGPT is shifting rightwards politically : r/technology \- Reddit, acessado em março 30, 2025, [https://www.reddit.com/r/technology/comments/1jlzjz3/chatgpt\_is\_shifting\_rightwards\_politically/](https://www.reddit.com/r/technology/comments/1jlzjz3/chatgpt_is_shifting_rightwards_politically/)  
37. ChatGPT is shifting rightwards politically : r/artificial \- Reddit, acessado em março 30, 2025, [https://www.reddit.com/r/artificial/comments/1jm08zi/chatgpt\_is\_shifting\_rightwards\_politically/](https://www.reddit.com/r/artificial/comments/1jm08zi/chatgpt_is_shifting_rightwards_politically/)  
38. The Linda Problem (Cognitive Bias) and ChatGPT : r/ArtificialInteligence \- Reddit, acessado em março 30, 2025, [https://www.reddit.com/r/ArtificialInteligence/comments/10rayd5/the\_linda\_problem\_cognitive\_bias\_and\_chatgpt/](https://www.reddit.com/r/ArtificialInteligence/comments/10rayd5/the_linda_problem_cognitive_bias_and_chatgpt/)  
39. ChatGPT's bias is obvious, and known. But, here's a few experiences, and issues, I've had with it. : r/TheDeprogram \- Reddit, acessado em março 30, 2025, [https://www.reddit.com/r/TheDeprogram/comments/1ep69tf/chatgpts\_bias\_is\_obvious\_and\_known\_but\_heres\_a/](https://www.reddit.com/r/TheDeprogram/comments/1ep69tf/chatgpts_bias_is_obvious_and_known_but_heres_a/)  
40. Finding ChatGPT's Bias for Nike. : r/videos \- Reddit, acessado em março 30, 2025, [https://www.reddit.com/r/videos/comments/12z12lk/finding\_chatgpts\_bias\_for\_nike/](https://www.reddit.com/r/videos/comments/12z12lk/finding_chatgpts_bias_for_nike/)  
41. \[OC\] Political Compass chart for all major AI LLM models : ChatGPT, Claude, Gemini, Grok, DeepSeek. (Read submission comment for more details) : r/dataisbeautiful \- Reddit, acessado em março 30, 2025, [https://www.reddit.com/r/dataisbeautiful/comments/1jc7k1u/oc\_political\_compass\_chart\_for\_all\_major\_ai\_llm/](https://www.reddit.com/r/dataisbeautiful/comments/1jc7k1u/oc_political_compass_chart_for_all_major_ai_llm/)  
42. Political Compass or Spinning Arrow? Towards More Meaningful Evaluations for Values and Opinions in Large Language Models \- ACL Anthology, acessado em março 30, 2025, [https://aclanthology.org/2024.acl-long.816/](https://aclanthology.org/2024.acl-long.816/)  
43. Something has changed recently with ChatGPT : r/ChatGPTPro \- Reddit, acessado em março 30, 2025, [https://www.reddit.com/r/ChatGPTPro/comments/1iaa7yy/something\_has\_changed\_recently\_with\_chatgpt/](https://www.reddit.com/r/ChatGPTPro/comments/1iaa7yy/something_has_changed_recently_with_chatgpt/)  
44. Have you noticed changes in ChatGPT? Exploring its evolution through interactions, acessado em março 30, 2025, [https://community.openai.com/t/have-you-noticed-changes-in-chatgpt-exploring-its-evolution-through-interactions/1134254](https://community.openai.com/t/have-you-noticed-changes-in-chatgpt-exploring-its-evolution-through-interactions/1134254)  
45. Strange behavior of the chat app during long discussions \- OpenAI Developer Forum, acessado em março 30, 2025, [https://community.openai.com/t/strange-behavior-of-the-chat-app-during-long-discussions/1135553](https://community.openai.com/t/strange-behavior-of-the-chat-app-during-long-discussions/1135553)  
46. Inconsistent Behavior with ChatGPT Personas Across Different Modes \- Bugs, acessado em março 30, 2025, [https://community.openai.com/t/inconsistent-behavior-with-chatgpt-personas-across-different-modes/1135644](https://community.openai.com/t/inconsistent-behavior-with-chatgpt-personas-across-different-modes/1135644)  
47. Ban chatGPT for answers and resources \- Developer Forum | Roblox, acessado em março 30, 2025, [https://devforum.roblox.com/t/ban-chatgpt-for-answers-and-resources/2091013?page=6](https://devforum.roblox.com/t/ban-chatgpt-for-answers-and-resources/2091013?page=6)  
48. ChatGPT's User Experience: What is Behind the Decline in Intelligence? \- Bugs, acessado em março 30, 2025, [https://community.openai.com/t/chatgpts-user-experience-what-is-behind-the-decline-in-intelligence/1081511](https://community.openai.com/t/chatgpts-user-experience-what-is-behind-the-decline-in-intelligence/1081511)  
49. Hello \+ Model Switching Within Chat \- Community \- OpenAI Developer Forum, acessado em março 30, 2025, [https://community.openai.com/t/hello-model-switching-within-chat/1140315](https://community.openai.com/t/hello-model-switching-within-chat/1140315)  
50. Political Bias in AI-Language Models: A Comparative Analysis of ChatGPT-4, Perplexity, Google Gemini, and Claude \- ResearchGate, acessado em março 30, 2025, [https://www.researchgate.net/publication/382322175\_Political\_Bias\_in\_AI-Language\_Models\_A\_Comparative\_Analysis\_of\_ChatGPT-4\_Perplexity\_Google\_Gemini\_and\_Claude](https://www.researchgate.net/publication/382322175_Political_Bias_in_AI-Language_Models_A_Comparative_Analysis_of_ChatGPT-4_Perplexity_Google_Gemini_and_Claude)  
51. Political Bias in AI-Language Models: A Comparative Analysis of ChatGPT-4, Perplexity, Google Gemini, and Claude \- Preprints.org, acessado em março 30, 2025, [https://www.preprints.org/manuscript/202407.1274/v1](https://www.preprints.org/manuscript/202407.1274/v1)  
52. Political Bias in Large Language Models: A Comparative Analysis | by Rajiv Gopinath, acessado em março 30, 2025, [https://medium.com/@mail2rajivgopinath/political-bias-in-large-language-models-a-comparative-analysis-a905b0b9015c](https://medium.com/@mail2rajivgopinath/political-bias-in-large-language-models-a-comparative-analysis-a905b0b9015c)  
53. arxiv.org, acessado em março 30, 2025, [https://arxiv.org/abs/2412.16746](https://arxiv.org/abs/2412.16746)  
54. (PDF) The Implications of Diverse Human Moral Foundations for Assessing the Ethicality of Artificial Intelligence \- ResearchGate, acessado em março 30, 2025, [https://www.researchgate.net/publication/358594796\_The\_Implications\_of\_Diverse\_Human\_Moral\_Foundations\_for\_Assessing\_the\_Ethicality\_of\_Artificial\_Intelligence](https://www.researchgate.net/publication/358594796_The_Implications_of_Diverse_Human_Moral_Foundations_for_Assessing_the_Ethicality_of_Artificial_Intelligence)  
55. Moral Foundations of Attitudes Towards Artificial Intelligence and Specific Concerns Regarding It. | Metadata \- OSF, acessado em março 30, 2025, [https://osf.io/jr3xv/metadata/](https://osf.io/jr3xv/metadata/)  
56. How convincing are AI-generated moral arguments for climate action? \- Frontiers, acessado em março 30, 2025, [https://www.frontiersin.org/journals/climate/articles/10.3389/fclim.2023.1193350/full](https://www.frontiersin.org/journals/climate/articles/10.3389/fclim.2023.1193350/full)  
57. MoralBench: Moral Evaluation of LLMs \- arXiv, acessado em março 30, 2025, [https://arxiv.org/html/2406.04428v1/](https://arxiv.org/html/2406.04428v1/)  
58. Are Large Language Models Moral Hypocrites? A Study Based on Moral Foundations | Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, acessado em março 30, 2025, [https://ojs.aaai.org/index.php/AIES/article/view/31704](https://ojs.aaai.org/index.php/AIES/article/view/31704)  
59. Evaluating ChatGPT's moral competence in health care-related ethical problems \- PMC, acessado em março 30, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC11233145/](https://pmc.ncbi.nlm.nih.gov/articles/PMC11233145/)  
60. Using ChatGPT to Enhance Students' Behavior in Social Media via the Moral Foundation Theory \- CEUR-WS, acessado em março 30, 2025, [https://ceur-ws.org/Vol-3605/7.pdf](https://ceur-ws.org/Vol-3605/7.pdf)  
61. Using ChatGPT to Enhance Students' Behavior in Social Media via the Moral Foundation Theory \- ResearchGate, acessado em março 30, 2025, [https://www.researchgate.net/publication/377224460\_Using\_ChatGPT\_to\_Enhance\_Students'\_Behavior\_in\_Social\_Media\_via\_the\_Moral\_Foundation\_Theory](https://www.researchgate.net/publication/377224460_Using_ChatGPT_to_Enhance_Students'_Behavior_in_Social_Media_via_the_Moral_Foundation_Theory)  
62. Locating the Ethics of ChatGPT—Ethical Issues as Affordances in AI Ecosystems \- MDPI, acessado em março 30, 2025, [https://www.mdpi.com/2078-2489/16/2/104](https://www.mdpi.com/2078-2489/16/2/104)  
63. Using core beliefs as a foundation for ethical behavior in AI \- OpenAI Developer Forum, acessado em março 30, 2025, [https://community.openai.com/t/using-core-beliefs-as-a-foundation-for-ethical-behavior-in-ai/1034553](https://community.openai.com/t/using-core-beliefs-as-a-foundation-for-ethical-behavior-in-ai/1034553)  
64. Moral Foundations of Large Language Models \- AAAI 2023 Workshop: Representation learning for Responsible Human-Centric AI, acessado em março 30, 2025, [https://r2hcai.github.io/AAAI-23/files/CameraReadys/49.pdf](https://r2hcai.github.io/AAAI-23/files/CameraReadys/49.pdf)  
65. Moral Foundations of Large Language Models \- Natasha Jaques, acessado em março 30, 2025, [https://natashajaques.ai/publication/moral-foundations-of-large-language-models/](https://natashajaques.ai/publication/moral-foundations-of-large-language-models/)  
66. Moral Foundational Characteristics of Large Language Models \- eScholarship, acessado em março 30, 2025, [https://escholarship.org/uc/item/9pn5q6g8](https://escholarship.org/uc/item/9pn5q6g8)  
67. Moral Foundations of Large Language Models \- ACL Anthology, acessado em março 30, 2025, [https://aclanthology.org/2024.emnlp-main.982.pdf](https://aclanthology.org/2024.emnlp-main.982.pdf)  
68. \[2310.15337\] Moral Foundations of Large Language Models \- arXiv, acessado em março 30, 2025, [https://arxiv.org/abs/2310.15337](https://arxiv.org/abs/2310.15337)  
69. Mapping and Influencing the Political Ideology of Large Language Models using Synthetic Personas \- arXiv, acessado em março 30, 2025, [https://arxiv.org/html/2412.14843v2](https://arxiv.org/html/2412.14843v2)  
70. Researchers show how AI tools can be tuned to reflect specific political ideologies, acessado em março 30, 2025, [https://engineering.brown.edu/news/2024-10-22/ai-tools-reflect-political-ideologies](https://engineering.brown.edu/news/2024-10-22/ai-tools-reflect-political-ideologies)  
71. Biased AI can Influence Political Decision-Making \- arXiv, acessado em março 30, 2025, [https://arxiv.org/html/2410.06415v1](https://arxiv.org/html/2410.06415v1)  
72. Researchers show how AI tools can be tuned to reflect specific political ideologies, acessado em março 30, 2025, [https://www.brown.edu/news/2024-10-22/ai-bias](https://www.brown.edu/news/2024-10-22/ai-bias)  
73. Only a Little to the Left: A Theory-grounded Measure of Political Bias in Large Language Models \- arXiv, acessado em março 30, 2025, [https://arxiv.org/html/2503.16148v1](https://arxiv.org/html/2503.16148v1)  
74. Breaking Down AI Bias Through Scaffolded Prompt Construction \- Notre Dame Learning, acessado em março 30, 2025, [https://learning.nd.edu/workshops-and-events/2025/01/27/breaking-down-ai-bias-through-scaffolded-prompt-construction/](https://learning.nd.edu/workshops-and-events/2025/01/27/breaking-down-ai-bias-through-scaffolded-prompt-construction/)  
75. PROPAGANDA: PRompt Organization and Political Analysis for Group Agent Networks and Distributed Architectures | by Daniel Rodríguez | sadasant | Medium, acessado em março 30, 2025, [https://medium.com/sadasant/propaganda-prompt-organization-and-political-analysis-for-group-agent-networks-and-distributed-6bc49e8bac56](https://medium.com/sadasant/propaganda-prompt-organization-and-political-analysis-for-group-agent-networks-and-distributed-6bc49e8bac56)  
76. Aligning Large Language Models with Diverse Political Viewpoints | PromptLayer, acessado em março 30, 2025, [https://www.promptlayer.com/research-papers/aligning-large-language-models-with-diverse-political-viewpoints](https://www.promptlayer.com/research-papers/aligning-large-language-models-with-diverse-political-viewpoints)  
77. Cultural bias and cultural alignment of large language models \- Oxford Academic, acessado em março 30, 2025, [https://academic.oup.com/pnasnexus/article/3/9/pgae346/7756548](https://academic.oup.com/pnasnexus/article/3/9/pgae346/7756548)  
78. Through the LLM Looking Glass: A Socratic Self-Assessment of Donkeys, Elephants, and Markets \- arXiv, acessado em março 30, 2025, [https://arxiv.org/html/2503.16674v1](https://arxiv.org/html/2503.16674v1)  
79. Evidence of political bias in ChatGPT? Researchers reveal a hack to bypass it \- AS USA, acessado em março 30, 2025, [https://en.as.com/latest\_news/evidence-of-political-bias-in-chatgpt-researchers-reveal-a-hack-to-bypass-it-n/](https://en.as.com/latest_news/evidence-of-political-bias-in-chatgpt-researchers-reveal-a-hack-to-bypass-it-n/)  
80. Opportunities and challenges of AI-systems in political decision-making contexts \- Frontiers, acessado em março 30, 2025, [https://www.frontiersin.org/articles/10.3389/fpos.2025.1504520/full](https://www.frontiersin.org/articles/10.3389/fpos.2025.1504520/full)  
81. Addressing bias in AI | Center for Teaching Excellence \- The University of Kansas, acessado em março 30, 2025, [https://cte.ku.edu/addressing-bias-ai](https://cte.ku.edu/addressing-bias-ai)  
82. The Perils of Bias: Navigating Ethical Challenges in AI-Driven Politivacs \- Sage Journals, acessado em março 30, 2025, [https://journals.sagepub.com/doi/10.1177/00953997251327162](https://journals.sagepub.com/doi/10.1177/00953997251327162)  
83. Algorithmic Political Bias in Artificial Intelligence Systems \- PMC \- PubMed Central, acessado em março 30, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC8967082/](https://pmc.ncbi.nlm.nih.gov/articles/PMC8967082/)  
84. Generative AI bias poses risk to democratic values \- EurekAlert\!, acessado em março 30, 2025, [https://www.eurekalert.org/news-releases/1072301](https://www.eurekalert.org/news-releases/1072301)  
85. What Is AI Alignment? \- IBM, acessado em março 30, 2025, [https://www.ibm.com/think/topics/ai-alignment](https://www.ibm.com/think/topics/ai-alignment)  
86. Evaluating fairness in ChatGPT \- OpenAI, acessado em março 30, 2025, [https://openai.com/index/evaluating-fairness-in-chatgpt/](https://openai.com/index/evaluating-fairness-in-chatgpt/)  
87. OpenAI CEO calls ChatGPT bias a 'flaw,' denies censorship allegations \- Social Samosa, acessado em março 30, 2025, [https://www.socialsamosa.com/news-2/openai-ceo-calls-chatgpt-bias-a-flaw-denies-censorship-allegations-8729063](https://www.socialsamosa.com/news-2/openai-ceo-calls-chatgpt-bias-a-flaw-denies-censorship-allegations-8729063)  
88. OpenAI removes 'politically unbiased' reference in policy update \- The Express Tribune, acessado em março 30, 2025, [https://tribune.com.pk/story/2522258/openai-updates-policy-removes-reference-to-politically-unbiased-model](https://tribune.com.pk/story/2522258/openai-updates-policy-removes-reference-to-politically-unbiased-model)  
89. OpenAI gives ChatGPT free speech \- ITdaily., acessado em março 30, 2025, [https://itdaily.com/news/innovation/chatgpt-free-speech/](https://itdaily.com/news/innovation/chatgpt-free-speech/)  
90. Model Spec (2025/02/12) \- OpenAI, acessado em março 30, 2025, [https://model-spec.openai.com/](https://model-spec.openai.com/)  
91. OpenAI updates ChatGPT policy for neutrality, diversity \- Tech in Asia, acessado em março 30, 2025, [https://www.techinasia.com/news/openai-updates-chatgpt-policy-neutrality-diversity](https://www.techinasia.com/news/openai-updates-chatgpt-policy-neutrality-diversity)  
92. OpenAI just updated its 187-page rulebook so ChatGPT can engage with more controversial topics | TechRadar, acessado em março 30, 2025, [https://www.techradar.com/computing/artificial-intelligence/openai-just-updated-its-187-page-rulebook-so-chatgpt-can-engage-with-more-controversial-topics](https://www.techradar.com/computing/artificial-intelligence/openai-just-updated-its-187-page-rulebook-so-chatgpt-can-engage-with-more-controversial-topics)  
93. OpenAI Announces ChatGPT Now Has Fewer Limits and More Freedom, acessado em março 30, 2025, [https://www.success.com/openai-chatgpt-fewer-limits/](https://www.success.com/openai-chatgpt-fewer-limits/)  
94. OpenAI Expands Model Specification: What It Means for AI Development | by Martijn Assie | AI Frontiers | Feb, 2025 | Medium, acessado em março 30, 2025, [https://medium.com/ai-frontiers/openai-expands-model-specification-what-it-means-for-ai-development-bf2e5cdaf175](https://medium.com/ai-frontiers/openai-expands-model-specification-what-it-means-for-ai-development-bf2e5cdaf175)  
95. OpenAI to uncensor ChatGPT from controversial viewpoints \- The American Bazaar, acessado em março 30, 2025, [https://americanbazaaronline.com/2025/02/18/openai-to-uncensor-chatgpt-from-controversial-viewpoints-459682/](https://americanbazaaronline.com/2025/02/18/openai-to-uncensor-chatgpt-from-controversial-viewpoints-459682/)  
96. How does OpenAI handle bias in its models? \- Milvus Blog, acessado em março 30, 2025, [https://blog.milvus.io/ai-quick-reference/how-does-openai-handle-bias-in-its-models](https://blog.milvus.io/ai-quick-reference/how-does-openai-handle-bias-in-its-models)  
97. Twin Studies Warn of Harmful Emotional and Social Impacts of ChatGPT \- AIwire, acessado em março 30, 2025, [https://www.aiwire.net/2025/03/26/twin-studies-warn-of-harmful-emotional-and-social-impacts-of-chatgpt/](https://www.aiwire.net/2025/03/26/twin-studies-warn-of-harmful-emotional-and-social-impacts-of-chatgpt/)  
98. Empirical assessment of ChatGPT's answering capabilities in natural science and engineering \- PMC, acessado em março 30, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC10904823/](https://pmc.ncbi.nlm.nih.gov/articles/PMC10904823/)  
99. Feedback on Political Neutrality and Bias in ChatGPT Responses, acessado em março 30, 2025, [https://community.openai.com/t/feedback-on-political-neutrality-and-bias-in-chatgpt-responses/1149388](https://community.openai.com/t/feedback-on-political-neutrality-and-bias-in-chatgpt-responses/1149388)  
100. Universal skepticism of ChatGPT: a review of early literature on chat generative pre-trained transformer \- PMC, acessado em março 30, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC10482048/](https://pmc.ncbi.nlm.nih.gov/articles/PMC10482048/)  
101. OpenAI Works to Loosen ChatGPT Restrictions Amid Censorship Concerns\! \- All About AI, acessado em março 30, 2025, [https://www.allaboutai.com/ai-news/openai-works-to-loosen-chatgpt-restrictions-amid-censorship-concerns/](https://www.allaboutai.com/ai-news/openai-works-to-loosen-chatgpt-restrictions-amid-censorship-concerns/)  
102. Political Neutrality in AI is Impossible — But Here is How to Approximate it \- arXiv, acessado em março 30, 2025, [https://arxiv.org/html/2503.05728v1](https://arxiv.org/html/2503.05728v1)  
103. OpenAI ChatGPT and Biased Information in Higher Education \- Texas A\&M University-San Antonio, acessado em março 30, 2025, [https://www.tamusa.edu/academics/ai-resources/documents/Open-AI-Chat-GPT-and-Bias-by-OBrien-and-Alsmadi.pdf](https://www.tamusa.edu/academics/ai-resources/documents/Open-AI-Chat-GPT-and-Bias-by-OBrien-and-Alsmadi.pdf)  
104. AI Neutrality in the Spotlight: ChatGPT's Political Biases Revisited, acessado em março 30, 2025, [https://montrealethics.ai/ai-neutrality-in-the-spotlight-chatgpts-political-biases-revisited/](https://montrealethics.ai/ai-neutrality-in-the-spotlight-chatgpts-political-biases-revisited/)  
105. Artificial Intelligence Neutrality: Framing Analysis of GPT Powered-Bing Chat and Google Bard \- ResearchGate, acessado em março 30, 2025, [https://www.researchgate.net/publication/373715801\_Artificial\_Intelligence\_Neutrality\_Framing\_Analysis\_of\_GPT\_Powered-Bing\_Chat\_and\_Google\_Bard](https://www.researchgate.net/publication/373715801_Artificial_Intelligence_Neutrality_Framing_Analysis_of_GPT_Powered-Bing_Chat_and_Google_Bard)  
106. Systemic Bias in AI Responses: Prioritizing Mainstream Narratives Over Accurarate Narratives \- Bugs \- OpenAI Developer Community, acessado em março 30, 2025, [https://community.openai.com/t/systemic-bias-in-ai-responses-prioritizing-mainstream-narratives-over-accurarate-narratives/1126897](https://community.openai.com/t/systemic-bias-in-ai-responses-prioritizing-mainstream-narratives-over-accurarate-narratives/1126897)  
107. \[2501.14294\] Examining Alignment of Large Language Models through Representative Heuristics: The Case of Political Stereotypes \- arXiv, acessado em março 30, 2025, [https://arxiv.org/abs/2501.14294](https://arxiv.org/abs/2501.14294)